{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "Load papers and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T08:53:09.394380Z",
     "iopub.status.busy": "2022-11-01T08:53:09.393959Z",
     "iopub.status.idle": "2022-11-01T08:53:10.828937Z",
     "shell.execute_reply": "2022-11-01T08:53:10.828194Z",
     "shell.execute_reply.started": "2022-11-01T08:53:09.394315Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/conda/feedstock_root/build_artifacts/aiobotocore_1661463101257/work\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/home/conda/feedstock_root/build_artifacts/aiobotocore_1661463101257/work'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T14:02:59.412619Z",
     "iopub.status.busy": "2022-11-01T14:02:59.412247Z",
     "iopub.status.idle": "2022-11-01T14:02:59.785961Z",
     "shell.execute_reply": "2022-11-01T14:02:59.785274Z",
     "shell.execute_reply.started": "2022-11-01T14:02:59.412595Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from redis.asyncio import Redis\n",
    "# from utils.embeddings import Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T14:03:01.998960Z",
     "iopub.status.busy": "2022-11-01T14:03:01.998477Z",
     "iopub.status.idle": "2022-11-01T14:03:02.002523Z",
     "shell.execute_reply": "2022-11-01T14:03:02.001981Z",
     "shell.execute_reply.started": "2022-11-01T14:03:01.998933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to the redis instance running in your docker stack at redis:6379\n",
    "# redis_conn = await Redis(host=\"redis\", port=\"6379\")\n",
    "# redis-16159.c21898.eu-west-1-1.ec2.cloud.rlrcp.com:16159\n",
    "# redis_conn = await Redis(host=\"redis\", port=\"6379\")\n",
    "# redis_conn = await Redis(host=\"redis-16159.c21898.eu-west-1-1.ec2.cloud.rlrcp.com\", port=\"16159\")\n",
    "redis_conn = await Redis(host=\"redis-16159.c21898.eu-west-1-1.ec2.cloud.rlrcp.com\", port=\"16159\", password=\"BAPmx2ATT6StewWs8YdSJUvcAPKtQ04M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T18:15:11.581197Z",
     "iopub.status.busy": "2022-10-29T18:15:11.580806Z",
     "iopub.status.idle": "2022-10-29T18:15:11.584120Z",
     "shell.execute_reply": "2022-10-29T18:15:11.583545Z",
     "shell.execute_reply.started": "2022-10-29T18:15:11.581172Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dir(redis_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T14:06:39.257406Z",
     "iopub.status.busy": "2022-11-01T14:06:39.257012Z",
     "iopub.status.idle": "2022-11-01T14:06:39.262782Z",
     "shell.execute_reply": "2022-11-01T14:06:39.262185Z",
     "shell.execute_reply.started": "2022-11-01T14:06:39.257381Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load papers dataframe\n",
    "def read_paper_df() -> pd.DataFrame:\n",
    "    with open(\"arxiv_papers_df.pkl\", \"rb\") as f:\n",
    "        df = pickle.load(f)\n",
    "    return df\n",
    "\n",
    "def paper_key(paper_id: str) -> str:\n",
    "    return f\"paper:{paper_id}\"\n",
    "\n",
    "# Function to concurrently load papers into Redis\n",
    "async def gather_with_concurrency(n, redis_conn, *papers):\n",
    "    semaphore = asyncio.Semaphore(n)\n",
    "    async def load_paper(paper):\n",
    "        async with semaphore:\n",
    "            paper[\"cat_embeddings\"] = np.array(paper[\"cat_embeddings\"], dtype=np.float32).tobytes()\n",
    "            await redis_conn.hset(paper_key(paper[\"id\"]), mapping=paper)\n",
    "    # gather with concurrency\n",
    "    await asyncio.gather(*[load_paper(p) for p in papers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T14:03:05.015889Z",
     "iopub.status.busy": "2022-11-01T14:03:05.015507Z",
     "iopub.status.idle": "2022-11-01T14:03:21.643522Z",
     "shell.execute_reply": "2022-11-01T14:03:21.642906Z",
     "shell.execute_reply.started": "2022-11-01T14:03:05.015862Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "      <th>count_cats</th>\n",
       "      <th>split_categories</th>\n",
       "      <th>categories_combined</th>\n",
       "      <th>cat_embeddings</th>\n",
       "      <th>kmean_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>2007</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>1</td>\n",
       "      <td>['High Energy Physics - Phenomenology']</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "      <td>[0.36575573682785034, -0.06158893555402756, -0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0016</td>\n",
       "      <td>Lifetime of doubly charmed baryons</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chao-Hsi Chang, Tong Li, Xue-Qian Li and Yu-Mi...</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>In this work, we evaluate the lifetimes of t...</td>\n",
       "      <td>1</td>\n",
       "      <td>['High Energy Physics - Phenomenology']</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "      <td>[0.36575573682785034, -0.06158893555402756, -0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0029</td>\n",
       "      <td>Understanding the Flavor Symmetry Breaking and...</td>\n",
       "      <td>2007</td>\n",
       "      <td>Zhan Shu, Xiao-Lin Chen and Wei-Zhen Deng</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>In $\\XQM$, a quark can emit Goldstone bosons...</td>\n",
       "      <td>1</td>\n",
       "      <td>['High Energy Physics - Phenomenology']</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "      <td>[0.36575573682785034, -0.06158893555402756, -0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0031</td>\n",
       "      <td>Crystal channeling of LHC forward protons with...</td>\n",
       "      <td>2007</td>\n",
       "      <td>V. M. Biryukov (Serpukhov, IHEP)</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>We show that crystal can trap a broad (x, x'...</td>\n",
       "      <td>1</td>\n",
       "      <td>['High Energy Physics - Phenomenology']</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "      <td>[0.36575573682785034, -0.06158893555402756, -0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0032</td>\n",
       "      <td>Probing non-standard neutrino interactions wit...</td>\n",
       "      <td>2007</td>\n",
       "      <td>A. Esteban-Pretel, R. Tom\\`as and J. W. F. Valle</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>We analyze the possibility of probing non-st...</td>\n",
       "      <td>1</td>\n",
       "      <td>['High Energy Physics - Phenomenology']</td>\n",
       "      <td>High Energy Physics - Phenomenology</td>\n",
       "      <td>[0.36575573682785034, -0.06158893555402756, -0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  year  \\\n",
       "0  0704.0001  Calculation of prompt diphoton production cros...  2007   \n",
       "1  0704.0016                 Lifetime of doubly charmed baryons  2008   \n",
       "2  0704.0029  Understanding the Flavor Symmetry Breaking and...  2007   \n",
       "3  0704.0031  Crystal channeling of LHC forward protons with...  2007   \n",
       "4  0704.0032  Probing non-standard neutrino interactions wit...  2007   \n",
       "\n",
       "                                             authors categories  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...     hep-ph   \n",
       "1  Chao-Hsi Chang, Tong Li, Xue-Qian Li and Yu-Mi...     hep-ph   \n",
       "2          Zhan Shu, Xiao-Lin Chen and Wei-Zhen Deng     hep-ph   \n",
       "3                   V. M. Biryukov (Serpukhov, IHEP)     hep-ph   \n",
       "4   A. Esteban-Pretel, R. Tom\\`as and J. W. F. Valle     hep-ph   \n",
       "\n",
       "                                            abstract  count_cats  \\\n",
       "0    A fully differential calculation in perturba...           1   \n",
       "1    In this work, we evaluate the lifetimes of t...           1   \n",
       "2    In $\\XQM$, a quark can emit Goldstone bosons...           1   \n",
       "3    We show that crystal can trap a broad (x, x'...           1   \n",
       "4    We analyze the possibility of probing non-st...           1   \n",
       "\n",
       "                          split_categories  \\\n",
       "0  ['High Energy Physics - Phenomenology']   \n",
       "1  ['High Energy Physics - Phenomenology']   \n",
       "2  ['High Energy Physics - Phenomenology']   \n",
       "3  ['High Energy Physics - Phenomenology']   \n",
       "4  ['High Energy Physics - Phenomenology']   \n",
       "\n",
       "                   categories_combined  \\\n",
       "0  High Energy Physics - Phenomenology   \n",
       "1  High Energy Physics - Phenomenology   \n",
       "2  High Energy Physics - Phenomenology   \n",
       "3  High Energy Physics - Phenomenology   \n",
       "4  High Energy Physics - Phenomenology   \n",
       "\n",
       "                                      cat_embeddings  kmean_clusters  \n",
       "0  [0.36575573682785034, -0.06158893555402756, -0...               6  \n",
       "1  [0.36575573682785034, -0.06158893555402756, -0...               6  \n",
       "2  [0.36575573682785034, -0.06158893555402756, -0...               6  \n",
       "3  [0.36575573682785034, -0.06158893555402756, -0...               6  \n",
       "4  [0.36575573682785034, -0.06158893555402756, -0...               6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate\n",
    "# df = read_paper_df()\n",
    "# df.head()\n",
    "\n",
    "df = pd.read_csv(\"df_merged_pca_embeds.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T00:10:08.588920Z",
     "iopub.status.busy": "2022-10-31T00:10:08.588522Z",
     "iopub.status.idle": "2022-10-31T00:10:08.593525Z",
     "shell.execute_reply": "2022-10-31T00:10:08.592849Z",
     "shell.execute_reply.started": "2022-10-31T00:10:08.588887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'year', 'authors', 'categories', 'abstract',\n",
       "       'count_cats', 'split_categories', 'categories_combined',\n",
       "       'cat_embeddings', 'kmean_clusters'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"input\"] = df.apply(lambda r: r.title + r.abstract, axis=1)\n",
    "# df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo we will take a small sample\n",
    "# df = df.sample(frac=0.1)\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Creation\n",
    "\n",
    "To create embeddings/vector representations of the papers, we will use a combination of the paper abstract and title fields and pass through an open source `SentenceTransformer` model (after some light preprocessing).\n",
    "\n",
    "Everything is wrapped into the `Embeddings` class and `gather_with_concurrency` function below to help make this cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embeddings\n",
    "embeddings = Embeddings()\n",
    "vectors = embeddings.make(df.input.to_list(), show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T00:20:54.761028Z",
     "iopub.status.busy": "2022-10-31T00:20:54.760640Z",
     "iopub.status.idle": "2022-10-31T00:22:17.128360Z",
     "shell.execute_reply": "2022-10-31T00:22:17.127712Z",
     "shell.execute_reply.started": "2022-10-31T00:20:54.761004Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"cat_embeddings\"] = df[\"cat_embeddings\"].map(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T00:20:24.883487Z",
     "iopub.status.busy": "2022-10-31T00:20:24.883189Z",
     "iopub.status.idle": "2022-10-31T00:20:24.889388Z",
     "shell.execute_reply": "2022-10-31T00:20:24.888885Z",
     "shell.execute_reply.started": "2022-10-31T00:20:24.883465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.36575573682785034, -0.06158893555402756, -0...\n",
       "1    [0.36575573682785034, -0.06158893555402756, -0...\n",
       "2    [0.36575573682785034, -0.06158893555402756, -0...\n",
       "3    [0.36575573682785034, -0.06158893555402756, -0...\n",
       "4    [0.36575573682785034, -0.06158893555402756, -0...\n",
       "Name: cat_embeddings, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vector\"] = vectors.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T15:47:56.451209Z",
     "iopub.status.busy": "2022-11-01T15:47:56.450823Z",
     "iopub.status.idle": "2022-11-01T15:48:01.242353Z",
     "shell.execute_reply": "2022-11-01T15:48:01.241734Z",
     "shell.execute_reply.started": "2022-11-01T15:47:56.451185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert dataframe to a dict\n",
    "papers = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T00:22:23.465074Z",
     "iopub.status.busy": "2022-10-31T00:22:23.464862Z",
     "iopub.status.idle": "2022-10-31T00:41:15.007655Z",
     "shell.execute_reply": "2022-10-31T00:41:15.007027Z",
     "shell.execute_reply.started": "2022-10-31T00:22:23.465055Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load papers to Redis\n",
    "await gather_with_concurrency(50, redis_conn, *papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T15:48:02.543967Z",
     "iopub.status.busy": "2022-11-01T15:48:02.543285Z",
     "iopub.status.idle": "2022-11-01T15:48:02.625910Z",
     "shell.execute_reply": "2022-11-01T15:48:02.625372Z",
     "shell.execute_reply.started": "2022-11-01T15:48:02.543939Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many items were stored\n",
    "await redis_conn.dbsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T14:06:42.798622Z",
     "iopub.status.busy": "2022-11-01T14:06:42.798251Z",
     "iopub.status.idle": "2022-11-01T14:06:42.899320Z",
     "shell.execute_reply": "2022-11-01T14:06:42.898758Z",
     "shell.execute_reply.started": "2022-11-01T14:06:42.798593Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'abstract': b'  The paper is devoted to hyperbolic (generally speaking, non-Lagrangian and\\nnonlinear) partial differential systems possessing a full set of differential\\noperators that map any function of one independent variable into a symmetry of\\nthe corresponding system. We demonstrate that a system has the above property\\nif and only if this system admits a full set of formal integrals (i.e.,\\ndifferential operators which map symmetries into integrals of the system). As a\\nconsequence, such systems possess both direct and inverse Noether operators (in\\nthe terminology of a work by B. Fuchssteiner and A.S. Fokas who have used these\\nterms for operators that map cosymmetries into symmetries and perform\\ntransformations in the opposite direction). Systems admitting Noether operators\\nare not exhausted by Euler-Lagrange systems and the systems with formal\\nintegrals. In particular, a hyperbolic system admits an inverse Noether\\noperator if a differential substitution maps this system into a system\\npossessing an inverse Noether operator.\\n',\n",
       " b'title': b'Formal Integrals and Noether Operators of Nonlinear Hyperbolic Partial\\n  Differential Systems Admitting a Rich Set of Symmetries',\n",
       " b'year': b'2017',\n",
       " b'split_categories': b\"['Exactly Solvable and Integrable Systems', 'Mathematical Physics', 'Mathematical Physics']\",\n",
       " b'id': b'1511.09418',\n",
       " b'kmean_clusters': b'16',\n",
       " b'categories_combined': b'Exactly Solvable and Integrable Systems Mathematical Physics Mathematical Physics',\n",
       " b'cat_embeddings': b'S)\\xcc>\\xa9\\r%\\xbd\\xfa\\x7fC?XB.\\xbe\\xdb\\x8a\\x04=-t\"\\xbe\\x11\\x19\\x03=\\xc4\\x0c\\x8e=3\\xa5\\xd0\\xbd\\x1cG\\xb3\\xbe\\x95\\x1c|=\\x03\\xab\\x88>p\\x1at\\xbd\\t;\\x07>\\x8d7\\x92\\xbd=E*>\\t\\x8e\\xc9\\xbd}\\xa2%\\xbd\\x91,r=\\x06\\xd7%\\xbe\\xd5\\xf10\\xbd\\xb8ro\\xbd\\x9a\\xa04\\xbd\\x9bE6=\\x980\\x18\\xbc\\x1e\\x01f=\\x87\\x16~=Xg7:K\\xe2=\\xbe)zv\\xbc\\xe1\\xcf\\x12\\xbe\\xec\\xc4\\x03:\\xd2\\xd6\\x10>S\\xa4\\xee=\\x1du\\x86\\xbc\\xdei*\\xbe\\xe8Q\\x02\\xbdx\\x8c\\x19\\xbdA\\x81&\\xbd\\xfb\\xec\\xc3<W6H<\\xa0\\xc7\\x08=\\x9fSr\\xbcO\\x1d\\xb0=\\xe1\\x05\\xc6<\\xf0c\\x7f=v\\x16K\\xbd9v\\xc7=\\xf2\\x82\\xf0;\\xe2\\x15\\x1a\\xbd\\xc2\\xed\\x1c=c\\xb2\\x0e\\xbc\\xc1\\xc1\\x03\\xbd]\\x02\\t=\\xc5\\xaf\\x06==\\xbdx\\xbc',\n",
       " b'authors': b'Sergey Ya. Startsev',\n",
       " b'categories': b'nlin.SI,math-ph,math.MP',\n",
       " b'count_cats': b'3'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a paper\n",
    "key = paper_key(df.sample(1)[\"id\"].iloc[0])\n",
    "await redis_conn.hgetall(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T14:06:52.225004Z",
     "iopub.status.busy": "2022-11-01T14:06:52.224620Z",
     "iopub.status.idle": "2022-11-01T14:06:52.228850Z",
     "shell.execute_reply": "2022-11-01T14:06:52.228306Z",
     "shell.execute_reply.started": "2022-11-01T14:06:52.224975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper:1511.09418\n"
     ]
    }
   ],
   "source": [
    "# print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RediSearch Index Creation\n",
    "\n",
    "Now time to create the search index over all of the documents we have now stored in Redis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add search index for categories!! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T15:48:38.218328Z",
     "iopub.status.busy": "2022-11-01T15:48:38.217965Z",
     "iopub.status.idle": "2022-11-01T15:48:38.232315Z",
     "shell.execute_reply": "2022-11-01T15:48:38.231711Z",
     "shell.execute_reply.started": "2022-11-01T15:48:38.218302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# from config import INDEX_NAME\n",
    "from redis.asyncio import Redis\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "from redis.commands.search.field import VectorField\n",
    "from typing import Optional, Pattern\n",
    "INDEX_NAME = \"papers\"\n",
    "\n",
    "\n",
    "class TokenEscaper:\n",
    "    \"\"\"\n",
    "    Escape punctuation within an input string. Taken from RedisOM Python.\n",
    "    \"\"\"\n",
    "    # Characters that RediSearch requires us to escape during queries.\n",
    "    # Source: https://redis.io/docs/stack/search/reference/escaping/#the-rules-of-text-field-tokenization\n",
    "    DEFAULT_ESCAPED_CHARS = r\"[,.<>{}\\[\\]\\\\\\\"\\':;!@#$%^&*()\\-+=~\\/ ]\"\n",
    "\n",
    "    def __init__(self, escape_chars_re: Optional[Pattern] = None):\n",
    "        if escape_chars_re:\n",
    "            self.escaped_chars_re = escape_chars_re\n",
    "        else:\n",
    "            self.escaped_chars_re = re.compile(self.DEFAULT_ESCAPED_CHARS)\n",
    "\n",
    "    def escape(self, value: str) -> str:\n",
    "        def escape_symbol(match):\n",
    "            value = match.group(0)\n",
    "            return f\"\\\\{value}\"\n",
    "\n",
    "        return self.escaped_chars_re.sub(escape_symbol, value)\n",
    "\n",
    "class SearchIndexCat:\n",
    "    \"\"\"\n",
    "    SearchIndex is used to wrap and capture all information\n",
    "    and actions applied to a RediSearch index including creation,\n",
    "    manegement, and query construction.\n",
    "    \"\"\"\n",
    "    escaper = TokenEscaper()\n",
    "\n",
    "    async def create_flat(\n",
    "        self,\n",
    "        *fields,\n",
    "        redis_conn: Redis,\n",
    "        number_of_vectors: int,\n",
    "        prefix: str,\n",
    "        distance_metric: str='L2'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create a FLAT aka brute force style index.\n",
    "\n",
    "        Args:\n",
    "            redis_conn (Redis): Redis connection object.\n",
    "            number_of_vectors (int): Count of the number of initial vectors.\n",
    "            prefix (str): key prefix to use for RediSearch index creation.\n",
    "            distance_metric (str, optional): Distance metric to use for Vector Search. Defaults to 'L2'.\n",
    "        \"\"\"\n",
    "        vector_field = VectorField(\n",
    "            \"vector\",\n",
    "            \"FLAT\", {\n",
    "                \"TYPE\": \"FLOAT32\",\n",
    "                \"DIM\": 56,\n",
    "                \"DISTANCE_METRIC\": distance_metric,\n",
    "                \"INITIAL_CAP\": number_of_vectors,\n",
    "                \"BLOCK_SIZE\": number_of_vectors\n",
    "            }\n",
    "        )\n",
    "        await self._create(\n",
    "            *fields,\n",
    "            vector_field,\n",
    "            redis_conn=redis_conn,\n",
    "            prefix=prefix\n",
    "        )\n",
    "\n",
    "    async def create_hnsw(\n",
    "        self,\n",
    "        *fields,\n",
    "        redis_conn: Redis,\n",
    "        number_of_vectors: int,\n",
    "        prefix: str,\n",
    "        distance_metric: str='COSINE'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create an approximate NN index via HNSW.\n",
    "\n",
    "        Args:\n",
    "            redis_conn (Redis): Redis connection object.\n",
    "            number_of_vectors (int): Count of the number of initial vectors.\n",
    "            prefix (str): key prefix to use for RediSearch index creation.\n",
    "            distance_metric (str, optional): Distance metric to use for Vector Search. Defaults to 'COSINE'.\n",
    "        \"\"\"\n",
    "        vector_field = VectorField(\n",
    "            \"vector\",\n",
    "            \"HNSW\", {\n",
    "                \"TYPE\": \"FLOAT32\",\n",
    "                \"DIM\": 56,\n",
    "                \"DISTANCE_METRIC\": distance_metric,\n",
    "                \"INITIAL_CAP\": number_of_vectors,\n",
    "            }\n",
    "        )\n",
    "        await self._create(\n",
    "            *fields,\n",
    "            vector_field,\n",
    "            redis_conn=redis_conn,\n",
    "            prefix=prefix\n",
    "        )\n",
    "\n",
    "    async def _create(\n",
    "        self,\n",
    "        *fields,\n",
    "        redis_conn: Redis,\n",
    "        prefix: str\n",
    "    ):\n",
    "        # Create Index\n",
    "        await redis_conn.ft(INDEX_NAME).create_index(\n",
    "            fields = fields,\n",
    "            definition= IndexDefinition(prefix=[prefix], index_type=IndexType.HASH)\n",
    "        )\n",
    "\n",
    "    def process_tags(self, categories: list, years: list) -> str:\n",
    "        \"\"\"\n",
    "        Helper function to process tags data. TODO - factor this\n",
    "        out so it's agnostic to the name of the field.\n",
    "\n",
    "        Args:\n",
    "            categories (list): List of categories.\n",
    "            years (list): List of years.\n",
    "\n",
    "        Returns:\n",
    "            str: RediSearch tag query string.\n",
    "        \"\"\"\n",
    "        tag = \"(\"\n",
    "        if years:\n",
    "            years = \"|\".join([self.escaper.escape(year) for year in years])\n",
    "            tag += f\"(@year:{{{years}}})\"\n",
    "        if categories:\n",
    "            categories = \"|\".join([self.escaper.escape(cat) for cat in categories])\n",
    "            if tag:\n",
    "                tag += f\" (@categories:{{{categories}}})\"\n",
    "            else:\n",
    "                tag += f\"(@categories:{{{categories}}})\"\n",
    "        tag += \")\"\n",
    "        # if no tags are selected\n",
    "        if len(tag) < 3:\n",
    "            tag = \"*\"\n",
    "        return tag\n",
    "\n",
    "    def vector_query(\n",
    "        self,\n",
    "        categories: list,\n",
    "        years: list,\n",
    "        search_type: str=\"KNN\",\n",
    "        number_of_results: int=20\n",
    "    ) -> Query:\n",
    "        \"\"\"\n",
    "        Create a RediSearch query to perform hybrid vector and tag based searches.\n",
    "\n",
    "\n",
    "        Args:\n",
    "            categories (list): List of categories.\n",
    "            years (list): List of years.\n",
    "            search_type (str, optional): Style of search. Defaults to \"KNN\".\n",
    "            number_of_results (int, optional): How many results to fetch. Defaults to 20.\n",
    "\n",
    "        Returns:\n",
    "            Query: RediSearch Query\n",
    "\n",
    "        \"\"\"\n",
    "        # Parse tags to create query\n",
    "        tag_query = self.process_tags(categories, years)\n",
    "        base_query = f'{tag_query}=>[{search_type} {number_of_results} @vector $vec_param AS vector_score]'\n",
    "        return Query(base_query)\\\n",
    "            .sort_by(\"vector_score\")\\\n",
    "            .paging(0, number_of_results)\\\n",
    "            .return_fields(\"paper_id\", \"paper_pk\", \"vector_score\")\\\n",
    "            .dialect(2)\n",
    "\n",
    "    def count_query(\n",
    "        self,\n",
    "        years: list,\n",
    "        categories: list\n",
    "    ) -> Query:\n",
    "        \"\"\"\n",
    "        Create a RediSearch query to count available documents.\n",
    "\n",
    "        Args:\n",
    "            categories (list): List of categories.\n",
    "            years (list): List of years.\n",
    "\n",
    "        Returns:\n",
    "            Query: RediSearch Query\n",
    "        \"\"\"\n",
    "        # Parse tags to create query\n",
    "        tag_query = self.process_tags(categories, years)\n",
    "        return Query(f'{tag_query}')\\\n",
    "            .no_content()\\\n",
    "            .dialect(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T15:49:53.101343Z",
     "iopub.status.busy": "2022-11-01T15:49:53.100934Z",
     "iopub.status.idle": "2022-11-01T15:49:53.104818Z",
     "shell.execute_reply": "2022-11-01T15:49:53.104280Z",
     "shell.execute_reply.started": "2022-11-01T15:49:53.101316Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from redis.commands.search.field import (\n",
    "    TagField,\n",
    "    VectorField,\n",
    "    NumericField,\n",
    "    TextField\n",
    ")\n",
    "# from utils.search_index import SearchIndex\n",
    "\n",
    "# Search index helper class\n",
    "# search_index = SearchIndexCat(\"papers\", redis_conn)\n",
    "search_index = SearchIndexCat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T00:46:17.795804Z",
     "iopub.status.busy": "2022-10-31T00:46:17.795405Z",
     "iopub.status.idle": "2022-10-31T00:46:17.800096Z",
     "shell.execute_reply": "2022-10-31T00:46:17.799568Z",
     "shell.execute_reply.started": "2022-10-31T00:46:17.795779Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"cat_embeddings\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T15:57:47.415269Z",
     "iopub.status.busy": "2022-11-01T15:57:47.414882Z",
     "iopub.status.idle": "2022-11-01T15:57:47.497124Z",
     "shell.execute_reply": "2022-11-01T15:57:47.496489Z",
     "shell.execute_reply.started": "2022-11-01T15:57:47.415243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a document schema that includes 3 indexed fields\n",
    "# --> vector, categories, and year\n",
    "\n",
    "# vector_field = VectorField(\n",
    "#     \"vector\",\n",
    "#     \"HNSW\", {\n",
    "#         \"TYPE\": \"FLOAT32\",\n",
    "#         \"DIM\": 768,\n",
    "#         \"DISTANCE_METRIC\": \"COSINE\",\n",
    "#         \"INITIAL_CAP\": len(papers),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "vector_field = VectorField(\n",
    "    \"cat_embeddings\",\n",
    "    \"FLAT\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        # \"DIM\": 768,\n",
    "        \"DIM\": 56,\n",
    "        \"DISTANCE_METRIC\": \"COSINE\",\n",
    "        \"INITIAL_CAP\": len(papers),\n",
    "        \"BLOCK_SIZE\": len(papers)\n",
    "    }\n",
    ")\n",
    "categories_field = TagField(\"categories\")\n",
    "year_field = TagField(\"year\")\n",
    "\n",
    "# Create the index with the schema and over documents containing the prefix \"paper:\"\n",
    "await search_index.create_flat(\n",
    "    categories_field,\n",
    "    year_field,\n",
    "    vector_field,\n",
    "    redis_conn=redis_conn,\n",
    "    number_of_vectors=len(papers),\n",
    "    prefix=\"paper:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test queries!\n",
    "\n",
    "Use the [`running_queries.ipynb`](running_queries.ipynb) notebook to test out queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T16:46:36.471566Z",
     "iopub.status.busy": "2022-11-01T16:46:36.471180Z",
     "iopub.status.idle": "2022-11-01T16:46:36.475032Z",
     "shell.execute_reply": "2022-11-01T16:46:36.474479Z",
     "shell.execute_reply.started": "2022-11-01T16:46:36.471541Z"
    }
   },
   "outputs": [],
   "source": [
    "async def fetch_one(redis_conn):\n",
    "    async for key in redis_conn.scan_iter(\"paper:*\"):\n",
    "        return await redis_conn.hgetall(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T16:46:36.861302Z",
     "iopub.status.busy": "2022-11-01T16:46:36.860929Z",
     "iopub.status.idle": "2022-11-01T16:46:37.017341Z",
     "shell.execute_reply": "2022-11-01T16:46:37.016727Z",
     "shell.execute_reply.started": "2022-11-01T16:46:36.861277Z"
    }
   },
   "outputs": [],
   "source": [
    "paper = await fetch_one(redis_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insurance Claims Example\n",
    "\n",
    "The above code works for the demo dataset or arXiv papers! Extending the example to another use case, we can see how this might work for insurance claims and policy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First delete the other dataset from Redis...\n",
    "await search_index.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claims Schema\n",
    "# Here we assume some insurance claims might have a schema like this:\n",
    "\n",
    "claims_index = SearchIndex(\"claims\", redis_conn)\n",
    "\n",
    "# Sample dummy data\n",
    "claims = [{\n",
    "    \"claims_id\": \"1235\",\n",
    "    \"customer_id\": \"5341345\",\n",
    "    \"timestamp_of_incident\": 1665765963, # Epoch timestamp\n",
    "    \"timestamp_of_submission\": 1666716363,\n",
    "    \"claim_description\": \"This includes written text that describes the incident from the customer's POV\",\n",
    "    \"text_vector\": np.random.random(size=786),\n",
    "    \"age_of_customer\": 33\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with this data in RediSearch, we need to construct a schema and create an index\n",
    "\n",
    "# Schema Definitions\n",
    "customer = TagField(\"customer_id\") # to be able to filter/sort by customer ID\n",
    "timestamp_of_incident = NumericField(\"timestamp_of_incident\")\n",
    "timestamp_of_submission = NumericField(\"timestamp_of_submission\")\n",
    "claim_description = TextField(\"claim_description\")\n",
    "text_vector = VectorField(\n",
    "    \"text_vector\",\n",
    "    \"FLAT\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": 768,\n",
    "        \"DISTANCE_METRIC\": \"IP\",\n",
    "        \"INITIAL_CAP\": len(claims),\n",
    "        \"BLOCK_SIZE\": len(claims)\n",
    "    }\n",
    ")\n",
    "age_of_customer = NumericField(\"age_of_customer\")\n",
    "\n",
    "\n",
    "# Create Index\n",
    "await claims_index.create(\n",
    "    customer,\n",
    "    timestamp_of_incident,\n",
    "    timestamp_of_submission,\n",
    "    claim_description,\n",
    "    age_of_customer,\n",
    "    text_vector,\n",
    "    prefix=\"claim:\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to above, we also need to load data to Redis\n",
    "\n",
    "def claim_key(claim_id: str) -> str:\n",
    "    return f\"claim:{claim_id}\"\n",
    "\n",
    "for claim in claims:\n",
    "    claim[\"text_vector\"] = np.asarray(claim[\"text_vector\"], dtype=np.float32).tobytes()\n",
    "    await redis_conn.hset(claim_key(claim[\"claims_id\"]), mapping=claim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await redis_conn.hgetall(f\"claim:{claim['claims_id']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c5a7c9cc0d58080444e081b74a0823c09a12f0209aca730c38726ea6940124"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
